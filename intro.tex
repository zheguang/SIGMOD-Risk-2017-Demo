\section{Introduction}
\label{sec:intro}
 In the era of Big Data, visualization arises as an important mean to explore and derive insights from data.  However, visualized information such as relationships and trends may emerge from random noise.  Without proper statistical control, users may mistake visually significant observations as statistically significant.  Worse yet, systems that search and recommend visualized information would produce large number of questionable insights.  
A recent study shows that visualization and recommendation without considering the risk of false discovery, such as Vizdom~\cite{vizdom}, SeeDB~\cite{seedb} and Data Polygamy~\cite{polygamy}, becomes unusable on datasets with any randomness \cite{towards-sustainable-insight}.

\sam{insert figures} False discovery due to random noise is pervasive in visual data exploration on real-world datasets. For example, in a recently conducted survey on personal habits and opinions~\cite{towards-sustainable-insight}, the disbelief in alien existence combining with the preference of potato chips produces visually different proportion of workspace preferences, as visualized on Vizdom~\cite{vizdom}.  But such predictor proves not only conceptually questionable but also statistically insignificant in its correlation to the prediction.  More alarmingly, more and more such observation-based hypotheses may be formulated as the user continues to explore the dataset, and hence quickly increase the expected number of false discoveries. For an example of the same survey, after searching through a few different comparisons, we stumbled upon a visualization that suggests hair color predicts whether one knows about Michael Stonebraker, and it would be statistically significant if considered as a lone hypothesis. This phenomenon is often referred to as data dredging or $p$-hacking~\cite{p-hacking}, and formally known as the multiple comparison problem~\cite{shaffer1995multiple}.

Several challenges exist to control the false discoveries in interactive data exploration.  To begin with, most statisticians evaluate hypotheses in a passive computing environment such as R~\cite{R}. In visual data exploration, the system also needs to assist the user in the hypothesis formulation and the hypothesis test selection. Secondly, interactive data exploration generates hypotheses dynamically to follow the process of human decision making.  However the traditional statistical procedures such as Bonferroni~\cite{bonferroni1936teoria} and Sequential FDR~\cite{seq-fdr} are not dynamic in that they require knowing all the hypotheses a priori before finalizing the inference on statistical significance.  Moreover, these traditional techniques assume complete pass of the data, and hence would delay user interaction on larger datasets.  We believe that progressive computation as an appealing paradigm for Big Data visualization~\cite{emanuel-user-study, online-aggregation, vizdom}.  Thus, we implemented a recent advance on interactive false discovery control procedure in data exploration that is both dynamic and progressive~\cite{controlling-false-discoveries}.

In summary, we present \system{} as our solution based on Vizdom~\cite{vizdom} that addresses the aforementioned challenges, namely,
\begin{itemize}
    \item To formulate hypotheses via user interaction;
    \item To visualize the statistical significance and other contextual information for each observation;
    \item To control multiple hypotheses dynamically during data exploration;
    \item To progressively compute the risk of false discovery.
\end{itemize}
